{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: dockerfile=Dockerfile\n",
      "env: account=533155507761\n",
      "env: region=us-west-2\n",
      "env: repo_name=ocr\n",
      "env: image_tag=prj_scsk\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import os \n",
    "import sagemaker\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Define instance configurations \n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "repo_name = 'ocr' # ECR repository\n",
    "image_tag = 'prj_scsk' # ECR image tag\n",
    "base_job_name = 'scsk-lionelocr' # SageMaker training prefix\n",
    "# dockerfile = os.path.abspath('./new_dockerfile')\n",
    "\n",
    "%env dockerfile Dockerfile\n",
    "%env account {account}\n",
    "%env region {region}\n",
    "%env repo_name {repo_name}\n",
    "%env image_tag {image_tag}\n",
    "\n",
    "# print(\"Account: {0}\".format(account))\n",
    "# print(\"Region: {0}\".format(region))\n",
    "# print(\"Repo name: {0}\".format(repo_name))\n",
    "# print(\"Image tag: {0}\".format(image_tag))\n",
    "# print(\"Base job name: {0}\".format(base_job_name))\n",
    "# print(\"Docker file: {0}\".format(dockerfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "aws ecr describe-repositories --repository-names $repo_name > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "   aws ecr create-repository --repository-name $repo_name > /dev/null\n",
    "fi\n",
    "$(aws ecr get-login --region $region --no-include-email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  795.6kB\n",
      "Step 1/19 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> a686b859d874\n",
      "Step 2/19 : ARG py_version=3\n",
      " ---> Using cache\n",
      " ---> 98aaf73178a3\n",
      "Step 3/19 : RUN test $py_version || exit 1\n",
      " ---> Using cache\n",
      " ---> 30fb40336673\n",
      "Step 4/19 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         cmake         curl         jq         libsm6         libxext6         libxrender-dev         nginx &&     if [ $py_version -eq 3 ];        then apt-get install -y --no-install-recommends python3.6-dev            && ln -s -f /usr/bin/python3.6 /usr/bin/python;        else apt-get install -y --no-install-recommends python-dev; fi &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 694b213bbc7e\n",
      "Step 5/19 : RUN cd /tmp &&     curl -O https://bootstrap.pypa.io/get-pip.py &&     python get-pip.py && rm get-pip.py\n",
      " ---> Using cache\n",
      " ---> abc6a0c16d38\n",
      "Step 6/19 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> a367420ef88e\n",
      "Step 7/19 : ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1 PYTHONIOENCODING=UTF-8 LANG=C.UTF-8 LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 700969d669b1\n",
      "Step 8/19 : RUN apt-get update     && apt-get install -y git\n",
      " ---> Using cache\n",
      " ---> a310821d1361\n",
      "Step 9/19 : RUN rm -rf /opt/ml/code/\n",
      " ---> Using cache\n",
      " ---> 657c41cac7c2\n",
      "Step 10/19 : COPY . /opt/ml/code/\n",
      " ---> 5d64a8189909\n",
      "Step 11/19 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in 9a156627a8c5\n",
      "Removing intermediate container 9a156627a8c5\n",
      " ---> 2b4a22197c09\n",
      "Step 12/19 : RUN rm -rf /root/.cache\n",
      " ---> Running in c20e986f5e02\n",
      "Removing intermediate container c20e986f5e02\n",
      " ---> afd3bc413f70\n",
      "Step 13/19 : RUN rm -rf /var/lib/apt/lists/* ~/.cache/pip\n",
      " ---> Running in 606a9e4a61e9\n",
      "Removing intermediate container 606a9e4a61e9\n",
      " ---> 5da8d8e62a55\n",
      "Step 14/19 : RUN apt-get autoremove && apt-get clean\n",
      " ---> Running in 44d8999f83a4\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Removing intermediate container 44d8999f83a4\n",
      " ---> 4edb155e2ca4\n",
      "Step 15/19 : RUN unlink /etc/localtime\n",
      " ---> Running in bfe3716892e3\n",
      "Removing intermediate container bfe3716892e3\n",
      " ---> 3e2e533e2d1c\n",
      "Step 16/19 : RUN ln -s /usr/share/zoneinfo/Asia/Ho_Chi_Minh /etc/localtime\n",
      " ---> Running in 64c9c04a1dd5\n",
      "Removing intermediate container 64c9c04a1dd5\n",
      " ---> 823b22719afc\n",
      "Step 17/19 : WORKDIR /opt/ml/code/\n",
      " ---> Running in 314e351328b4\n",
      "Removing intermediate container 314e351328b4\n",
      " ---> e7517cb7935d\n",
      "Step 18/19 : ENV export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64\n",
      " ---> Running in 497ed886ea64\n",
      "Removing intermediate container 497ed886ea64\n",
      " ---> 22ebc00e771c\n",
      "Step 19/19 : ENTRYPOINT [\"python\", \"main.py\", \"--config\", \"configs/sagemaker_config.json\"]\n",
      " ---> Running in aa6b8d75b866\n",
      "Removing intermediate container aa6b8d75b866\n",
      " ---> 9123553ffe40\n",
      "Successfully built 9123553ffe40\n",
      "Successfully tagged prj_scsk:latest\n",
      "REPOSITORY                                               TAG                             IMAGE ID            CREATED                  SIZE\n",
      "prj_scsk                                                 latest                          9123553ffe40        Less than a second ago   2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         latest                          9123553ffe40        Less than a second ago   2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          2db5ead99f19        6 minutes ago            2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          2ea5f086a820        14 minutes ago           2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          351ceb9a3e5f        21 minutes ago           2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          84aca8bff259        28 minutes ago           2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/anson-ocr   latest                          47f1415f8d32        32 minutes ago           4.05GB\n",
      "nvidia/cuda                                              10.0-cudnn7-devel-ubuntu16.04   edbd625b9042        5 days ago               3.11GB\n",
      "nvidia/cuda                                              9.0-cudnn7-devel-ubuntu16.04    a686b859d874        5 days ago               2.72GB\n",
      "The push refers to repository [533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr]\n",
      "\n",
      "\u001b[1B9b120ec3: Preparing \n",
      "\u001b[1B04e30d48: Preparing \n",
      "\u001b[1B7649d947: Preparing \n",
      "\u001b[1B9cd8eadc: Preparing \n",
      "\u001b[1B8d4b6c20: Preparing \n",
      "\u001b[1B7d179008: Preparing \n",
      "\u001b[1Bf399d0cf: Preparing \n",
      "\u001b[1B38cc43b6: Preparing \n",
      "\u001b[1Bf3957978: Preparing \n",
      "\u001b[1B7eca86c2: Preparing \n",
      "\u001b[1B3d00e3e2: Preparing \n",
      "\u001b[1Bcef4ab1b: Preparing \n",
      "\u001b[1B3277e2ee: Preparing \n",
      "\u001b[1B62c32538: Preparing \n",
      "\u001b[1Baf8eabd8: Preparing \n",
      "\u001b[1B0239569d: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[15Bd179008: Pushed lready exists 5kB16A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[20A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[Klatest: digest: sha256:35e9183da981cb9cd4c541c517077a2acb2c39518ae3e08614879c0f7cc4e3c8 size: 4507\n"
     ]
    }
   ],
   "source": [
    "# # Build docker and push to ionstance\n",
    "# subprocess.run(\"docker build -t {0} -f {1} . \".format(image_tag, dockerfile), shell=True)\n",
    "# subprocess.run(\"docker tag {0} {1}.dkr.ecr.{2}.amazonaws.com/{3}:latest\".format(image_tag, account, region, repo_name), shell=True)\n",
    "# subprocess.run(\"docker push {0}.dkr.ecr.{1}.amazonaws.com/{2}:latest\".format(account, region, repo_name), shell=True)\n",
    "\n",
    "!docker build -t $image_tag -f $dockerfile .\n",
    "!docker tag $image_tag $account.dkr.ecr.$region.amazonaws.com/$repo_name:latest\n",
    "!docker images\n",
    "!docker push $account.dkr.ecr.$region.amazonaws.com/$repo_name:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data path in S3 \n",
    "s3_directory = 's3://scsk-data/ocr_data/data'\n",
    "train_input_channel = sagemaker.session.s3_input(s3_directory, distribution='FullyReplicated',  s3_data_type='S3Prefix')\n",
    "\n",
    "# Define image name, output path to save model \n",
    "output_path = 's3://scsk-data/ocr_data/output/lionel'\n",
    "image_name  = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, repo_name)\n",
    "\n",
    "## Define instance to train \n",
    "train_instance_type = 'ml.p3.2xlarge'\n",
    "# train_instance_type = 'ml.p3.8xlarge'\n",
    "\n",
    "# Define space of disk to storage input data\n",
    "storage_space = 200 # Gb\n",
    "\n",
    "# Maximum seconds for this training jobâ€™s life (days * hours * seconds)\n",
    "train_max_run = 1 * 24  * 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-05 05:05:12 Starting - Starting the training job...\n",
      "2019-08-05 05:05:14 Starting - Launching requested ML instances......\n",
      "2019-08-05 05:06:21 Starting - Preparing the instances for training......\n",
      "2019-08-05 05:07:27 Downloading - Downloading input data...\n",
      "2019-08-05 05:08:04 Training - Downloading the training image......\n",
      "2019-08-05 05:09:10 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mInstalling requirements...\u001b[0m\n",
      "\u001b[31mCollecting tensorflow-gpu (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\u001b[0m\n",
      "\u001b[31mCollecting keras (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\u001b[0m\n",
      "\u001b[31mCollecting numpy (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\u001b[0m\n",
      "\u001b[31mCollecting tqdm (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\u001b[0m\n",
      "\u001b[31mCollecting opencv-python (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\u001b[0m\n",
      "\u001b[31mCollecting comet_ml (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/52/11f789dbf6e757a9831ad54c0850d2a0c2822866e65e899a94bba8e824b2/comet_ml-2.0.5-py3-none-any.whl (111kB)\u001b[0m\n",
      "\u001b[31mCollecting scikit-learn (from -r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\u001b[0m\n",
      "\u001b[31mCollecting pillow (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\u001b[0m\n",
      "\u001b[31mCollecting editdistance (from -r requirements.txt (line 9))\n",
      "  Downloading https://files.pythonhosted.org/packages/77/67/2b1fe72bdd13ee9ec32b97959d7dfbfcd7c0548081d69aaf8493c1e695f9/editdistance-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (178kB)\u001b[0m\n",
      "\u001b[31mCollecting dotmap (from -r requirements.txt (line 10))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/a6/0f88e89673285daf190891985ad8b57d1d70ec4ccaf2d53b692e25f52ad4/dotmap-1.3.8-py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting google-pasta>=0.1.6 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\u001b[0m\n",
      "\u001b[31mCollecting keras-applications>=1.0.6 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\u001b[0m\n",
      "\u001b[31mCollecting six>=1.10.0 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting astor>=0.6.0 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting keras-preprocessing>=1.0.5 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\u001b[0m\n",
      "\u001b[31mCollecting absl-py>=0.7.0 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\u001b[0m\n",
      "\u001b[31mCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\u001b[0m\n",
      "\u001b[31mCollecting grpcio>=1.8.6 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/5d/b434403adb2db8853a97828d3d19f2032e79d630e0d11a8e95d243103a11/grpcio-1.22.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\u001b[0m\n",
      "\u001b[31mCollecting protobuf>=3.6.1 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/0e/e7cdff89745986c984ba58e6ff6541bc5c388dd9ab9d7d312b3b1532584a/protobuf-3.9.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->-r requirements.txt (line 1)) (0.33.4)\u001b[0m\n",
      "\u001b[31mCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow-gpu->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\u001b[0m\n",
      "\u001b[31mCollecting wrapt>=1.11.1 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting gast>=0.2.0 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting termcolor>=1.1.0 (from tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting h5py (from keras->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\u001b[0m\n",
      "\u001b[31mCollecting pyyaml (from keras->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\u001b[0m\n",
      "\u001b[31mCollecting scipy>=0.14 (from keras->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\u001b[0m\n",
      "\u001b[31mCollecting everett[ini]>=1.0.1; python_version >= \"3.0\" (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting websocket-client>=0.55.0 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\u001b[0m\n",
      "\u001b[31mCollecting comet-git-pure>=0.19.11 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/48/ae/a3d9b28e1d909bddbdba8ef7c331542614f3bf9fbba31bd4380c3294c569/comet_git_pure-0.19.11-py3-none-any.whl (383kB)\u001b[0m\n",
      "\u001b[31mCollecting jsonschema>=2.6.0 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/54/48/f5f11003ceddcd4ad292d4d9b5677588e9169eef41f88e38b2888e7ec6c4/jsonschema-3.0.2-py2.py3-none-any.whl (54kB)\u001b[0m\n",
      "\u001b[31mCollecting requests>=2.18.4 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\u001b[0m\n",
      "\u001b[31mCollecting wurlitzer>=1.0.2 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/09/56/201c4d13c37b6fb0cb5dbf1d026a2fec14fd151fd4f3f1dc1144d6273fd3/wurlitzer-1.0.3-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting nvidia-ml-py3>=7.352.0 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting netifaces>=0.10.7 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\u001b[0m\n",
      "\u001b[31mCollecting joblib>=0.11 (from scikit-learn->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu->-r requirements.txt (line 1)) (41.0.1)\u001b[0m\n",
      "\u001b[31mCollecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\u001b[0m\n",
      "\u001b[31mCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\u001b[0m\n",
      "\u001b[31mCollecting configobj; extra == \"ini\" (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting certifi (from comet-git-pure>=0.19.11->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl (157kB)\u001b[0m\n",
      "\u001b[31mCollecting urllib3>=1.23 (from comet-git-pure>=0.19.11->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)\u001b[0m\n",
      "\u001b[31mCollecting attrs>=17.4.0 (from jsonschema>=2.6.0->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting pyrsistent>=0.14.0 (from jsonschema>=2.6.0->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/66/b2638d96a2d128b168d0dba60fdc77b7800a9b4a5340cefcc5fc4eae6295/pyrsistent-0.15.4.tar.gz (107kB)\u001b[0m\n",
      "\u001b[31mCollecting chardet<3.1.0,>=3.0.2 (from requests>=2.18.4->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\u001b[0m\n",
      "\u001b[31mCollecting idna<2.9,>=2.5 (from requests>=2.18.4->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: absl-py, wrapt, gast, termcolor, pyyaml, nvidia-ml-py3, configobj, pyrsistent\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.7.1-cp36-none-any.whl size=117848 sha256=f194a27e3b782ada0aefe959cf8f80999a7da74dbc901532f8153aefbea80214\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for wrapt (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=64266 sha256=24cb3ea9e936db78dea00f24c960b812b2fefbf2c17b778b1ac63c613f67a0f4\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for gast (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7541 sha256=018faeebbf79559ac7ac3e74325cf4cb99b07db61da453fc8300148c4098f6d8\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4833 sha256=a84aac7ffed3cfdbcabaa330b30717421b657e222c1542dbd113023ead185f77\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for pyyaml (setup.py): started\n",
      "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44105 sha256=1ee6bc1c81908208224f7f225d7a817334da5d0ef5e41d8f543641d49c038718\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-cp36-none-any.whl size=19193 sha256=aca3837730c537b6da847584d49fb7e0ad4344b7c92a30a3c4f9db8c13d81763\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "  Building wheel for configobj (setup.py): started\n",
      "  Building wheel for configobj (setup.py): finished with status 'done'\n",
      "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34547 sha256=1c27c54f3b9264708221cabe2a83a9d2437cb5465213b4feb735f7c903ba457b\n",
      "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.15.4-cp36-cp36m-linux_x86_64.whl size=94338 sha256=6751a93a4f8f9d49ad73e9cd93f2a6f1fedcd5362fb63c5013df1a7d2e56f7bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/46/00/6d471ef0b813e3621f0abe6cb723c20d529d39a061de3f7c51\u001b[0m\n",
      "\u001b[31mSuccessfully built absl-py wrapt gast termcolor pyyaml nvidia-ml-py3 configobj pyrsistent\u001b[0m\n",
      "\u001b[31mInstalling collected packages: google-pasta, numpy, six, h5py, keras-applications, astor, keras-preprocessing, absl-py, tensorflow-estimator, grpcio, protobuf, werkzeug, markdown, tensorboard, wrapt, gast, termcolor, tensorflow-gpu, pyyaml, scipy, keras, tqdm, opencv-python, configobj, everett, websocket-client, certifi, urllib3, comet-git-pure, attrs, pyrsistent, jsonschema, chardet, idna, requests, wurlitzer, nvidia-ml-py3, netifaces, comet-ml, joblib, scikit-learn, pillow, editdistance, dotmap\u001b[0m\n",
      "\u001b[31mSuccessfully installed absl-py-0.7.1 astor-0.8.0 attrs-19.1.0 certifi-2019.6.16 chardet-3.0.4 comet-git-pure-0.19.11 comet-ml-2.0.5 configobj-5.0.6 dotmap-1.3.8 editdistance-0.5.3 everett-1.0.2 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 h5py-2.9.0 idna-2.8 joblib-0.13.2 jsonschema-3.0.2 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 netifaces-0.10.9 numpy-1.17.0 nvidia-ml-py3-7.352.0 opencv-python-4.1.0.25 pillow-6.1.0 protobuf-3.9.0 pyrsistent-0.15.4 pyyaml-5.1.2 requests-2.22.0 scikit-learn-0.21.3 scipy-1.3.0 six-1.12.0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 termcolor-1.1.0 tqdm-4.32.2 urllib3-1.25.3 websocket-client-0.56.0 werkzeug-0.15.5 wrapt-1.11.2 wurlitzer-1.0.3\u001b[0m\n",
      "\u001b[31mDoing unzip file /opt/ml/input/data/train/data.zip:\u001b[0m\n",
      "\n",
      "2019-08-05 05:10:41 Uploading - Uploading generated training model\u001b[31mMon Aug  5 05:10:37 2019       \u001b[0m\n",
      "\u001b[31m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[31m| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\u001b[0m\n",
      "\u001b[31m|-------------------------------+----------------------+----------------------+\u001b[0m\n",
      "\u001b[31m| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[31m| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[31m|===============================+======================+======================|\u001b[0m\n",
      "\u001b[31m|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[31m| N/A   39C    P0    27W / 300W |      0MiB / 16130MiB |      0%      Default |\u001b[0m\n",
      "\u001b[31m+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \u001b[0m\n",
      "\u001b[31m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[31m| Processes:                                                       GPU Memory |\u001b[0m\n",
      "\u001b[31m|  GPU       PID   Type   Process name                             Usage      |\u001b[0m\n",
      "\u001b[31m|=============================================================================|\u001b[0m\n",
      "\u001b[31m|  No running processes found                                                 |\u001b[0m\n",
      "\u001b[31m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[31mRUN TRAIN.PY FILE\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[31mBuilding vocabulary\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"train.py\", line 46, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 25, in main\n",
      "    config.n_letters = build_vocab(config)\n",
      "  File \"/opt/ml/code/utils/ocr_utils.py\", line 13, in build_vocab\n",
      "    _, val_labels = get_image_paths_and_labels(get_data_path(config, config.data.val_json_path))\n",
      "  File \"/opt/ml/code/utils/ocr_utils.py\", line 42, in get_image_paths_and_labels\n",
      "    with open(json_path, 'r', encoding='utf-8') as f:\u001b[0m\n",
      "\u001b[31mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/train/data/Japanese/val.json'\u001b[0m\n",
      "\n",
      "2019-08-05 05:10:47 Completed - Training job completed\n",
      "Billable seconds: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set sagemaker estimator and process to train\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "                       image_name=image_name,\n",
    "                       base_job_name=base_job_name,\n",
    "                       role=role,\n",
    "                       input_mode='File',\n",
    "                       train_instance_count=1,\n",
    "                       train_volume_size=storage_space,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       output_path=output_path,\n",
    "                       train_max_run=train_max_run,\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "estimator.fit({'train': train_input_channel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
